{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3622d34c-dd6f-410d-8196-f5884bd7836a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Snowpark For Python\n",
    "\n",
    "### In this session, we will cover:\n",
    "\n",
    "* Snowpark for Python Installation\n",
    "* Creating Session object and connecting to Snowflake\n",
    "* Reading and loading data from Snowflake table into Snowpark DataFrame\n",
    "* Perfoming Exploratory Data Analysis (EDA) on Snowpark DataFrame\n",
    "* Creating User-Defined Function (UDF)\n",
    "* Using pre-trained scikit-learn model for inference in UDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd6fec",
   "metadata": {},
   "source": [
    "### Snowpark For Python Installation\n",
    "- conda create --name snowpark -c https://repo.anaconda.com/pkgs/snowflake python=3.8\n",
    "- conda activate snowpark\n",
    "- pip install \"snowflake-snowpark-python[pandas]\"\n",
    "- pip install ipykernel\n",
    "- pip install cachetools\n",
    "- pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21210110-09fb-41ed-a248-1ce6b1f21b47",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80562f60-bf0a-40cb-bd12-55f8066f595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowpark\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.functions import udf, count, col, year, call_udf, array_construct\n",
    "from snowflake.snowpark.types import Variant\n",
    "from snowflake.snowpark.version import VERSION\n",
    "# Misc\n",
    "import pandas as pd\n",
    "import json\n",
    "from cachetools import cached\n",
    "\n",
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecf9295-1fa3-4d77-8fb5-da71cab73475",
   "metadata": {},
   "source": [
    "### Establish Secure Connection to Snowflake\n",
    "\n",
    "##### *Options: Username/Password, MFA, OAuth, Okta, SSO*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2da9f106-f5b5-42a6-a341-22f282077484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warehouse                   : DASH_XL\n",
      "Database                    : DASH_DB\n",
      "Schema                      : DASH_SCHEMA\n",
      "Snowflake version           : 6.18.3\n",
      "Snowpark for Python version : 0.7.0\n"
     ]
    }
   ],
   "source": [
    "connection_parameters = json.load(open('../connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "\n",
    "snowflake_environment = session.sql('select current_warehouse(), current_database(), current_schema(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('Warehouse                   : {}'.format(snowflake_environment[0][0]))\n",
    "print('Database                    : {}'.format(snowflake_environment[0][1]))\n",
    "print('Schema                      : {}'.format(snowflake_environment[0][2]))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][3]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61a1f8e-7d9f-46fc-940e-85d0731e82b8",
   "metadata": {},
   "source": [
    "### Load Amazon Reviews data from Snowflake table into Snowpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79dcb70b-4c34-47df-aef1-d26588d0af5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"MARKETPLACE\"  |\"REVIEW_ID\"     |\"PRODUCT_ID\"  |\"PRODUCT_PARENT\"  |\"PRODUCT_TITLE\"                                     |\"PRODUCT_CATEGORY\"  |\"STAR_RATING\"  |\"HELPFUL_VOTES\"  |\"TOTAL_VOTES\"  |\"VINE\"  |\"VERIFIED_PURCHASE\"  |\"REVIEW_HEADLINE\"                                   |\"REVIEW_BODY\"                                       |\"REVIEW_DATE\"  |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|US             |R2W9DA68EPF0FV  |0679433740    |925934976         |Paradise                                            |Books               |3              |0                |1              |N       |N                    |complex but enjoyable                               |I read this book for a book club assignment.  I...  |1998-07-06     |\n",
      "|US             |R2PQMUNTNC11BT  |0670880728    |738261988         |Bridget Jones's Diary                               |Books               |5              |1                |1              |N       |N                    |When are they bringing out Diary #2?  Keep 'em ...  |I thought that Bridget was so completely and ut...  |1998-07-06     |\n",
      "|US             |R1H3J29NUX6YV0  |0060920084    |754387444         |The Lost Continent: Travels in Small-Town America   |Books               |3              |5                |7              |N       |N                    |Clever but cruel                                    |Bryson's breakneck tour through small American ...  |1998-07-06     |\n",
      "|US             |R16TBQZL8TQTO2  |0553208845    |36215520          |Siddhartha                                          |Books               |5              |0                |0              |N       |N                    |A Beautiful Story                                   |This book is so wonderfully written that it tak...  |1998-07-06     |\n",
      "|US             |RW3PHHVONKQRK   |B000006NPY    |940428624         |Adore                                               |Music               |4              |0                |0              |N       |N                    |You'll adore it!                                    |It's different from the other cd's, but it's a ...  |1998-07-06     |\n",
      "|US             |R1SU6AE9W0XRNU  |B000002N2P    |820995200         |Green Day - Insomniac                               |Music               |1              |3                |22             |N       |N                    |I wish I could give it ZERO stars                   |This album is a discrace to music.  It is a dis...  |1998-07-07     |\n",
      "|US             |R5IT6PFPOFYTO   |B000002NHN    |95315084          |The Book of Secrets                                 |Music               |5              |0                |0              |N       |N                    |Even in michigan, we love it                        |Loreena McKennitt does it again with a compilat...  |1998-07-07     |\n",
      "|US             |RL790PTSRIVWA   |0783880871    |529898130         |Unnatural Exposure                                  |Books               |1              |0                |0              |N       |N                    |A sloppy effort, too many loose ends.. unsatisf...  |Half a star would do actually ... PC tries to i...  |1998-07-07     |\n",
      "|US             |R17DHSAWYNIBD7  |B000002LIM    |375271481         |Batman: Original Motion Picture Score               |Music               |5              |2                |2              |N       |N                    |One of the All-Time Great Movie Themes              |Danny Elfman has composed a wonderfully origina...  |1998-07-07     |\n",
      "|US             |R2FEX1S8FAHSDZ  |0887306667    |381720534         |The 22 Immutable Laws of Marketing:  Violate Th...  |Books               |4              |1                |1              |N       |N                    |The Marketing Cooking book                          |A well written book about classic marketing app...  |1998-07-07     |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df = session.table(\"SUMMIT_AMAZON_REVIEWS_DB.DASH_SCHEMA.AMAZON_REVIEWS\")\n",
    "snow_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd56c3a-75a6-4166-b940-4d65d512d2f2",
   "metadata": {},
   "source": [
    "### Number of records per STAR_RATING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5da3775a-a8ea-4398-b93f-676a1fa1422c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "|\"STAR_RATING\"  |\"COUNT(STAR_RATING)\"  |\n",
      "----------------------------------------\n",
      "|5              |16697                 |\n",
      "|1              |1709                  |\n",
      "|3              |1612                  |\n",
      "|2              |1155                  |\n",
      "|4              |3827                  |\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df.group_by('STAR_RATING').agg(count('STAR_RATING')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed13bd",
   "metadata": {},
   "source": [
    "### Number of records per PRODUCT_CATEGORY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41315521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "|\"PRODUCT_CATEGORY\"  |\"COUNT(PRODUCT_CATEGORY)\"  |\n",
      "--------------------------------------------------\n",
      "|Video               |1751                       |\n",
      "|Books               |6640                       |\n",
      "|Camera              |5000                       |\n",
      "|Video DVD           |721                        |\n",
      "|Music               |5888                       |\n",
      "|Watches             |5000                       |\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df.group_by('PRODUCT_CATEGORY').agg(count('PRODUCT_CATEGORY')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71314391-e130-44fe-b3dc-f2a8be023e4c",
   "metadata": {},
   "source": [
    "### Number of STAR_RATINGs per YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f3b1acf-0ee8-49cf-84b3-9a7b8d7b2f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "|\"YEAR\"  |\"TOTAL_RATINGS\"  |\n",
      "----------------------------\n",
      "|1995    |9                |\n",
      "|1996    |192              |\n",
      "|1997    |1753             |\n",
      "|1998    |11274            |\n",
      "|1999    |1772             |\n",
      "|2015    |10000            |\n",
      "----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df.group_by(year('REVIEW_DATE')).agg(count('STAR_RATING').as_('TOTAL_RATINGS')).with_column_renamed('YEAR(REVIEW_DATE)','YEAR').sort('YEAR').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf78ccc-3132-42a7-b029-c26d89abdb9d",
   "metadata": {},
   "source": [
    "### Missing data ... rows with no STAR_RATING or REVIEW_BODY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8380095-9ced-4e08-b6f4-fc9686123007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "|\"REVIEW_ID\"     |\"STAR_RATING\"  |\"REVIEW_BODY\"  |\n",
      "--------------------------------------------------\n",
      "|R3R885VN6USBYM  |5              |NULL           |\n",
      "|R3GKZOOU9MQIB8  |5              |NULL           |\n",
      "|R26LKY7Y8QG2Y2  |1              |NULL           |\n",
      "|R3QXY2UIFIUEYI  |4              |NULL           |\n",
      "|R2OJE1F0QFYC8E  |5              |NULL           |\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_df = snow_df.filter(col('STAR_RATING').is_null() | col('REVIEW_BODY').is_null()).select(['REVIEW_ID','STAR_RATING','REVIEW_BODY'])\n",
    "temp_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa2fb0f",
   "metadata": {},
   "source": [
    "#### >>>>>>>>>> *Examine Snowpark DataFrame Query* <<<<<<<<<< "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d941dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'queries': ['SELECT \"REVIEW_ID\", \"STAR_RATING\", \"REVIEW_BODY\" FROM ( SELECT  *  FROM ( SELECT  *  FROM (SUMMIT_AMAZON_REVIEWS_DB.DASH_SCHEMA.AMAZON_REVIEWS)) WHERE (\"STAR_RATING\" IS NULL OR \"REVIEW_BODY\" IS NULL))'],\n",
       " 'post_actions': []}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9086b6a2-a017-4717-bf48-f07157536a0b",
   "metadata": {},
   "source": [
    "### Data cleanup -- Remove rows with null values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b86b88fd-7471-4e34-8698-3e5540313b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records before cleanup    :  25000\n",
      "Records after cleanup     :  24994\n",
      "Number of records removed :  6\n"
     ]
    }
   ],
   "source": [
    "records_before = snow_df.count()\n",
    "print('Records before cleanup    : ',records_before)\n",
    "\n",
    "# Delete rows with missing values\n",
    "snow_df = snow_df.dropna()\n",
    "\n",
    "# Filter out rows with no STAR_RATING or REVIEW_BODY\n",
    "snow_df = snow_df.filter(col('STAR_RATING').is_not_null() | col('REVIEW_BODY').is_not_null())\n",
    "\n",
    "records_after = snow_df.count()\n",
    "print('Records after cleanup     : ',records_after)\n",
    "print('Number of records removed : ',(records_before - records_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b8865-af18-4b1c-b4b3-8f45d73375a3",
   "metadata": {},
   "source": [
    "### User-Defined Function (UDF) for Text Processing Using spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fb54bb-80ba-49f8-a584-3fbbf0afc9ed",
   "metadata": {},
   "source": [
    "* Upload external dependency to an internal stage\n",
    "* Add dependency to the Session for the UDF\n",
    "* Create UDF with additional packages from Snowflake Anaconda Channel\n",
    "* Call UDF on Amaxon Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87dfc422-fdd9-4432-ad7d-a077694146d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The version of package spacy in the local environment is 3.2.3, which does not fit the criteria for the requirement spacy==2.3.5. Your UDF might not work when the package version is different between the server and your local environment\n"
     ]
    }
   ],
   "source": [
    "# Upload dependencies to a stage\n",
    "session.sql(\"create or replace stage dash_udf_imports\").collect()\n",
    "session.file.put(\"file:///Users/ddesai/en_core_web_sm.zip\", \"@dash_udf_imports/\")\n",
    "\n",
    "# Add dependency to the Session for the UDF\n",
    "session.clear_imports()\n",
    "session.add_import('@dash_udf_imports/en_core_web_sm.zip.gz')\n",
    "\n",
    "# Function to download and extract English pipeline in spaCy\n",
    "@cached(cache={})\n",
    "def extract_en_core_web_sm(input_file: str, output_dir: str)-> object:\n",
    "    import zipfile\n",
    "    import spacy\n",
    "            \n",
    "    with zipfile.ZipFile(input_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_dir)\n",
    "        \n",
    "    # load and return the english language small model of spacy\n",
    "    nlp = spacy.load(output_dir + \"/en_core_web_sm/en_core_web_sm-2.3.0\")\n",
    "    return nlp \n",
    "\n",
    "# Create UDF with additional packages from Snowflake Anaconda Channel\n",
    "# -- Remove HTML, tokenize text, lemmatize verbs and remove stop words\n",
    "@udf(name='process_text',session=session,packages=['spacy==2.3.5','beautifulsoup4','cachetools==4.2.2'],replace=True,is_permanent=True,stage_location='dash_udfs')\n",
    "def process_text(text: str) -> str:\n",
    "    import os\n",
    "    import sys\n",
    "    from bs4 import BeautifulSoup \n",
    "    from spacy.tokenizer import Tokenizer\n",
    "                       \n",
    "    IMPORT_DIRECTORY_NAME = \"snowflake_import_directory\"\n",
    "    import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]\n",
    "    \n",
    "    input_file = import_dir + 'en_core_web_sm.zip'\n",
    "    output_dir = '/tmp/en_core_web_sm' + str(os.getpid())\n",
    "    \n",
    "    nlp = extract_en_core_web_sm(input_file,output_dir)\n",
    "    stop_words = nlp.Defaults.stop_words\n",
    "    tokenizer = Tokenizer(nlp.vocab)\n",
    "    \n",
    "    # strip html\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    \n",
    "    # tokenize\n",
    "    tokens = tokenizer(text)\n",
    "    \n",
    "    # lemmatize verbs and remove stop words\n",
    "    text = [str(t.lemma_) for t in tokens if (t.orth_) not in stop_words] \n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2714de9b",
   "metadata": {},
   "source": [
    "### >>>>>>>>>> *Examine Query History in Snowsight* <<<<<<<<<<"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58272f5",
   "metadata": {},
   "source": [
    "### Call UDF on Amazon Reviews -- optionally convert results into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed1e8a34-f092-4b0b-96c3-798cbf0af26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.2 ms, sys: 1.95 ms, total: 9.15 ms\n",
      "Wall time: 6.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVIEW_BODY</th>\n",
       "      <th>PROCESSED_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is the first 8 issues of the series. it is the starting point of all this... it also contains the sound of her wings. issue #8. which is the first appearance of death. and many peoples favorite issue. its not the best of the collected works. but its the start of them.</td>\n",
       "      <td>['8', 'issue', 'series.', 'start', 'point', 'this...', 'contain', 'sound', 'wings.', 'issue', '#8.', 'appearance', 'death.', 'people', 'favorite', 'issue.', 'well', 'collect', 'works.', 'start', 'them.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I've always been partial to immutable laws. The tape is entertaining, good car listening. The laws are clearly self evident once you've  heard them and you wonder why you didn't know  all that already and were about to go off and  do something stupid.  It's cheap, get it.</td>\n",
       "      <td>[\"I've\", 'partial', 'immutable', 'laws.', 'The', 'tape', 'entertaining,', 'good', 'car', 'listening.', 'The', 'law', 'clearly', 'self', 'evident', \"you've\", ' ', 'hear', 'wonder', \"didn't\", 'know', ' ', ' ', 'stupid.', ' ', \"It's\", 'cheap,', 'it.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a book about first contact with aliens, written by a prominent member of SETI, the Search for ExtraTerrestrial Intelligence. Sagan makes excellent use of  SETI's current search methods as well as his own  knowledge of astronomy and physics to bring a sense of  reality to the book. But above its literacy, philosophy,  and speculation, it is an entertaining story that is not  overshadowe...</td>\n",
       "      <td>['This', 'book', 'contact', 'aliens,', 'write', 'prominent', 'member', 'SETI,', 'Search', 'ExtraTerrestrial', 'Intelligence.', 'Sagan', 'make', 'excellent', 'use', ' ', \"SETI's\", 'current', 'search', 'method', ' ', 'knowledge', 'astronomy', 'physic', 'bring', 'sense', ' ', 'reality', 'book.', 'But', 'literacy,', 'philosophy,', ' ', 'speculation,', 'entertain', 'story', ' ', 'overshadow', 'gadg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is quite possibly *the* funniest book I have ever read.  Terry Pratchett is an absolute genius (read the Discworld books--NOW!),  and Gaiman manages to give the book the appropriate dark touches.  Brilliant</td>\n",
       "      <td>['This', 'possibly', '*the*', 'funny', 'book', 'I', 'read.', ' ', 'Terry', 'Pratchett', 'absolute', 'genius', '(read', 'Discworld', 'books--NOW!),', ' ', 'Gaiman', 'manage', 'book', 'appropriate', 'dark', 'touches.', ' ', 'Brilliant']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The story behind the book is almost better than the work. But make no mistake, the work will endure.</td>\n",
       "      <td>['The', 'story', 'book', 'well', 'work.', 'But', 'mistake,', 'work', 'endure.']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                       REVIEW_BODY  \\\n",
       "0                                                                                                                                this is the first 8 issues of the series. it is the starting point of all this... it also contains the sound of her wings. issue #8. which is the first appearance of death. and many peoples favorite issue. its not the best of the collected works. but its the start of them.   \n",
       "1                                                                                                                                 I've always been partial to immutable laws. The tape is entertaining, good car listening. The laws are clearly self evident once you've  heard them and you wonder why you didn't know  all that already and were about to go off and  do something stupid.  It's cheap, get it.   \n",
       "2  This is a book about first contact with aliens, written by a prominent member of SETI, the Search for ExtraTerrestrial Intelligence. Sagan makes excellent use of  SETI's current search methods as well as his own  knowledge of astronomy and physics to bring a sense of  reality to the book. But above its literacy, philosophy,  and speculation, it is an entertaining story that is not  overshadowe...   \n",
       "3                                                                                                                                                                                              This is quite possibly *the* funniest book I have ever read.  Terry Pratchett is an absolute genius (read the Discworld books--NOW!),  and Gaiman manages to give the book the appropriate dark touches.  Brilliant   \n",
       "4                                                                                                                                                                                                                                                                                                             The story behind the book is almost better than the work. But make no mistake, the work will endure.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                    PROCESSED_TEXT  \n",
       "0                                                                                                                                                                                                      ['8', 'issue', 'series.', 'start', 'point', 'this...', 'contain', 'sound', 'wings.', 'issue', '#8.', 'appearance', 'death.', 'people', 'favorite', 'issue.', 'well', 'collect', 'works.', 'start', 'them.']  \n",
       "1                                                                                                                                                         [\"I've\", 'partial', 'immutable', 'laws.', 'The', 'tape', 'entertaining,', 'good', 'car', 'listening.', 'The', 'law', 'clearly', 'self', 'evident', \"you've\", ' ', 'hear', 'wonder', \"didn't\", 'know', ' ', ' ', 'stupid.', ' ', \"It's\", 'cheap,', 'it.']  \n",
       "2  ['This', 'book', 'contact', 'aliens,', 'write', 'prominent', 'member', 'SETI,', 'Search', 'ExtraTerrestrial', 'Intelligence.', 'Sagan', 'make', 'excellent', 'use', ' ', \"SETI's\", 'current', 'search', 'method', ' ', 'knowledge', 'astronomy', 'physic', 'bring', 'sense', ' ', 'reality', 'book.', 'But', 'literacy,', 'philosophy,', ' ', 'speculation,', 'entertain', 'story', ' ', 'overshadow', 'gadg...  \n",
       "3                                                                                                                                                                       ['This', 'possibly', '*the*', 'funny', 'book', 'I', 'read.', ' ', 'Terry', 'Pratchett', 'absolute', 'genius', '(read', 'Discworld', 'books--NOW!),', ' ', 'Gaiman', 'manage', 'book', 'appropriate', 'dark', 'touches.', ' ', 'Brilliant']  \n",
       "4                                                                                                                                                                                                                                                                                                                                  ['The', 'story', 'book', 'well', 'work.', 'But', 'mistake,', 'work', 'endure.']  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_amazon_reviews = snow_df.limit(10).select('REVIEW_BODY', call_udf(\"process_text\", col(\"REVIEW_BODY\")).as_('PROCESSED_TEXT')).to_pandas()\n",
    "df_amazon_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18e59b4-4ce7-4728-aa44-935d6539b2c2",
   "metadata": {},
   "source": [
    "### Model Training in Snowflake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5ce0bc",
   "metadata": {},
   "source": [
    "#### Load Advertising Data into Snowpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79d9ff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "|\"TV\"   |\"Radio\"  |\"Newspaper\"  |\"Sales\"  |\n",
      "-------------------------------------------\n",
      "|230.1  |37.8     |69.2         |22.1     |\n",
      "|44.5   |39.3     |45.1         |10.4     |\n",
      "|17.2   |45.9     |69.3         |12.0     |\n",
      "|151.5  |41.3     |58.5         |16.5     |\n",
      "|180.8  |10.8     |58.4         |17.9     |\n",
      "|8.7    |48.9     |75.0         |7.2      |\n",
      "|57.5   |32.8     |23.5         |11.8     |\n",
      "|120.2  |19.6     |11.6         |13.2     |\n",
      "|8.6    |2.1      |1.0          |4.8      |\n",
      "|199.8  |2.6      |21.2         |15.6     |\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df_budgets = session.table('ADVERTISING_BUDGETS')\n",
    "snow_df_budgets.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a040d4b",
   "metadata": {},
   "source": [
    "#### Snowpark Python code to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbd815ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sales_prediction_model(session: Session, features_table: str) -> Variant:\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "    import os\n",
    "    from joblib import dump\n",
    "\n",
    "    # Load features\n",
    "    df = session.table(features_table).to_pandas()\n",
    "\n",
    "    # Preprocess the Numeric columns\n",
    "    # We apply PolynomialFeatures and StandardScaler preprocessing steps to the numeric columns. NOTE: High degrees can cause overfitting.\n",
    "    numeric_features = ['TV','Radio','Newspaper']\n",
    "    numeric_transformer = Pipeline(steps=[('poly',PolynomialFeatures(degree = 2)),('scaler', StandardScaler())])\n",
    "\n",
    "    # Combine the preprocessed step together using the Column Transformer module\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)])\n",
    "\n",
    "    # The next step is the integrate the features we just preprocessed with our Machine Learning algorithm to enable us to build a model\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),('classifier', LinearRegression())])\n",
    "    parameteres = {}\n",
    "\n",
    "    X = df.drop('Sales', axis = 1)\n",
    "    y = df['Sales']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "    model = GridSearchCV(pipeline, param_grid=parameteres, cv=10)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Upload trained model to a stage\n",
    "    model_output_dir = '/tmp'\n",
    "    model_file = os.path.join(model_output_dir, 'sales_model.joblib')\n",
    "    dump(model, model_file)\n",
    "    session.file.put(model_file, \"@dash_models\",overwrite=True)\n",
    "\n",
    "    # Return model R2 score on train and test data\n",
    "    return {\"R2 score on Train\": model.score(X_train, y_train),\"R2 score on Test\": model.score(X_test, y_test)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9048d",
   "metadata": {},
   "source": [
    "#### Test Python function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77d54f8b-8021-4065-a316-32b344b3386c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R2 score on Train': 0.9288133512730626, 'R2 score on Test': 0.9533174341074796}\n"
     ]
    }
   ],
   "source": [
    "print(train_sales_prediction_model(session,\"ADVERTISING_BUDGETS\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22263505",
   "metadata": {},
   "source": [
    "### Create Stored Procedure to deploy training code on Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be255759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.stored_procedure.StoredProcedure at 0x7f9ad8f73580>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sproc.register(func=train_sales_prediction_model,name=\"train_sales_prediction_model\",packages=['snowflake-snowpark-python','scikit-learn','joblib'],is_permanent=True,stage_location=\"@dash_sprocs\",replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba80e514",
   "metadata": {},
   "source": [
    "### Execute Stored Procedure to train model and deploy it on Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca9b909c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"R2 score on Test\": 0.9533174341074796,\n",
      "  \"R2 score on Train\": 0.9288133512730626\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(session.call('train_sales_prediction_model','ADVERTISING_BUDGETS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e3bc57",
   "metadata": {},
   "source": [
    "### >>>>>>>>>> *Examine Query History in Snowsight* <<<<<<<<<<"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2d4fc0",
   "metadata": {},
   "source": [
    "### Create User-Defined Function for Inference on Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eae5d98c-ab01-4b9d-bb58-00be7a22041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.clear_imports()\n",
    "session.clear_packages()\n",
    "\n",
    "# Add trained model as dependency\n",
    "session.add_import('@dash_models/sales_model.joblib.gz')\n",
    "\n",
    "@udf(name='predict_sales',session=session,packages=['pandas','joblib','scikit-learn'],replace=True,is_permanent=True,stage_location='@dash_udfs')\n",
    "def predict_sales(budget_allocations: list) -> float:\n",
    "    import sys\n",
    "    import pandas as pd\n",
    "    from joblib import load\n",
    "\n",
    "    IMPORT_DIRECTORY_NAME = \"snowflake_import_directory\"\n",
    "    import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]\n",
    "    \n",
    "    model_file = import_dir + 'sales_model.joblib.gz'\n",
    "\n",
    "    model = load(model_file)\n",
    "            \n",
    "    features = ['TV','Radio','Newspaper']\n",
    "    df = pd.DataFrame([budget_allocations], columns=features)\n",
    "    sales = round(model.predict(df)[0],2)\n",
    "\n",
    "    return sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a60f1b28-d4c9-435e-8455-271609a507c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "|\"TV\"   |\"RADIO\"  |\"NEWSPAPER\"  |\"PREDICTED_SALES\"  |\n",
      "-----------------------------------------------------\n",
      "|199.8  |2.6      |21.2         |16.2               |\n",
      "|180.8  |10.8     |58.4         |16.13              |\n",
      "|120.2  |19.6     |11.6         |13.69              |\n",
      "-----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = session.create_dataframe([[180.8,10.8,58.4],[120.2,19.6,11.6],[199.8,2.6,21.2]], schema=['TV','Radio','Newspaper'])\n",
    "test_df.select('TV','Radio','Newspaper', \n",
    "    call_udf(\"predict_sales\", array_construct(col(\"TV\"), col(\"Radio\"), col(\"Newspaper\"))).as_(\"PREDICTED_SALES\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b5dfd4",
   "metadata": {},
   "source": [
    "### >>>>>>>>>> *Examine Query History in Snowsight* <<<<<<<<<<"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62291ee0",
   "metadata": {},
   "source": [
    "# Code on GitHub\n",
    "\n",
    "### Python Notebook is available at https://github.com/iamontheinet/dash-at-summit-2020"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fb0a37530c0004d75c43dbcefc0b8b6ea2fdc6f87c96f7fd6f8cf43b3f551c7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('snowpark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
